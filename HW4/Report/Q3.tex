\documentclass[12pt]{article}
% \title{Assignment 1: CS 754, Advanced Image Processing}
\author{\textbf{Question 3}}
\date{}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{ulem}
\usepackage{enumitem}
\usepackage{float}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{bm}
\pagenumbering{gobble}

\usepackage[margin=0.5in]{geometry}
\begin{document}
\maketitle

\begin{itemize}
    \item How will you solve for the minimum of the following objective functions: (1) $J(\boldsymbol{A_r}) = \|\boldsymbol{A}-\boldsymbol{A_r}\|^2_F$, where $\boldsymbol{A}$ is a known $m \times n$ matrix of rank greater than $r$, and $\boldsymbol{A_r}$ is a rank-$r$ matrix, where $r < m, r < n$. (2) $J(\boldsymbol{R}) = \|\boldsymbol{A}-\boldsymbol{R} \boldsymbol{B}\|^2_F$, where $\boldsymbol{A} \in \mathbb{R}^{n \times m}, \boldsymbol{B} \in \mathbb{R}^{n \times m}, \boldsymbol{R} \in \mathbb{R}^{n \times n}, m > n$ and $\boldsymbol{R}$ is constrained to be orthonormal. Note that $\boldsymbol{A}$ and $\boldsymbol{B}$ are both known. \\
In both cases, explain briefly any one situation in image processing where the solution to such an optimization problem is required.
\end{itemize}
\vspace*{0.5cm}\\
\textbf{Answer:} \\
\begin{enumerate}
    \item We have to minimize the objective function $J(\boldsymbol{A_r})$ given by,
    \begin{gather*}
        J(\boldsymbol{A_r}) = \|\boldsymbol{A}-\boldsymbol{A_r}\|^2_F
    \end{gather*}
    such that $rank(\boldsymbol{A_r}) = r$.\\
    In this problem we are basically trying to find the best rank r approximation for the matrix $A$. The solution to this problem is given by Eckart-Young theorem. \\
    Suppose the singular value decomposition of the matrix $A$ is given as, 
    \begin{gather*}
        \boldsymbol{A} = \boldsymbol{U} \boldsymbol{\Sigma} \boldsymbol{V}^T
    \end{gather*}
    then, considering the r largest singular values and the corresponding singular vectors from $U$ and $V$, we can find the rank r approximation of $A$ as,
    \begin{gather*}
        \boldsymbol{A_r} = \boldsymbol{U}_r \boldsymbol{\Sigma}_r \boldsymbol{V}_r^T
    \end{gather*}
    where $\Sigma_r$ contains the largest $r$ singular values of $A$ and $\boldsymbol{U}_r$ and $\boldsymbol{V}_r$ are the corresponding $r$ columns of $U$ and $V$.\\

    \textbf{Application:} The low rank approximation of a matrix can be used for robust patch based denoising of images/videos. Small patches from different spatial regions of an image are quite similar to each other. This similarity can be exploited to reduce the noise in the image without
    strong assumptions on the statistical properties of noise. Following is the link to the paper, which uses the low rank approximation to denoise an image. \\
    \href{https://ieeexplore.ieee.org/document/5539849}{Low Rank Approximation for Image Denoising} \\

    \item In this part we have to minimize the objective function $J(\boldsymbol{R})$ given by,
    \begin{gather*}
        J(\boldsymbol{R}) = \|\boldsymbol{A}-\boldsymbol{R} \boldsymbol{B}\|^2_F
    \end{gather*} \\
    such that R is an orthonormal matrix, i.e. $R^T R = R R^T = I$.\\
    This is the Orthogonal Procrustes problem. \\
    Consider,
    \begin{equation*}
    \begin{split}
        \|\boldsymbol{A}-\boldsymbol{R} \boldsymbol{B}\|^2_F & = trace((\boldsymbol{A} - \boldsymbol{R} \boldsymbol{B})^T (\boldsymbol{A} - \boldsymbol{R} \boldsymbol{B})) \\
        & = trace(\boldsymbol{A}^T \boldsymbol{A} - 2 \boldsymbol{A}^T \boldsymbol{R} \boldsymbol{B} + \boldsymbol{B} \boldsymbol{B}^T )
    \end{split}
    \end{equation*}

    Hence,
    \begin{equation*}
        \begin{split}
             \min_{\boldsymbol{R} , \boldsymbol{B}} \|\boldsymbol{A}-\boldsymbol{R} \boldsymbol{B}\|^2_F & = 
             \min_{\boldsymbol{R} , \boldsymbol{B}} trace(\boldsymbol{A}^T \boldsymbol{A} - 2 \boldsymbol{A}^T \boldsymbol{R} \boldsymbol{B} + \boldsymbol{B} \boldsymbol{B}^T ) \\
             & = \max_{\boldsymbol{R} , \boldsymbol{B}} trace(\boldsymbol{A}^T \boldsymbol{R} \boldsymbol{B}) \\
             & = \max_{\boldsymbol{R} , \boldsymbol{B}} trace(\boldsymbol{R}\boldsymbol{B}\boldsymbol{A}^T) \dots (\because trace(AB) = trace(BA)) \\
             & = \max trace(\boldsymbol{R} \boldsymbol{U} \boldsymbol{S} \boldsymbol{V}^T)
        \end{split}
        \end{equation*}
        This last equality is using the SVD of $BA^T = USV^T$\\
        Hence, 

        \begin{equation*}
            \begin{split}
                \min_{\boldsymbol{R} , \boldsymbol{B}} \|\boldsymbol{A}-\boldsymbol{R} \boldsymbol{B}\|^2_F & =
                \max trace(\boldsymbol{S} \boldsymbol{V}^T \boldsymbol{R} \boldsymbol{U} ) \dots (\because trace(AB) = trace(BA)) \\
                & = \max trace(\boldsymbol{S} \boldsymbol{X} ) \\
            \end{split}
        \end{equation*}
where $X = \boldsymbol{V}^T \boldsymbol{R} \boldsymbol{U}$ is an orthogonal matrix. \\
Now, 
\begin{equation*}
    \begin{split}
        trace(\boldsymbol{S} \boldsymbol{X} ) & = \sum_i S_{ii} X_{ii} \\
    \end{split}
\end{equation*}
Since, values $S_{ii}$ are non-negative, and the above expression is maximized if $X_{ii} = 1$ all along its diagonal. As $X$ is orthonormal, we must have 
\begin{gather*}
    \boldsymbol{X} = \boldsymbol{I} \\
    \implies \boldsymbol{V}^T \boldsymbol{R} \boldsymbol{U} = \boldsymbol{I} \\
    \implies  \boldsymbol{R} =  \boldsymbol{V} \boldsymbol{U}^T \\
\end{gather*}

\textbf{Application} : We saw one application of this problem in Tomography. In tomography under unknown angles for 3D images, we are trying to find the best rotation matrix $R$ such that the error in the reconstruction is minimized. In determining the best rotation matrix, we use the Orthogonal Procrustes problem. \\

\end{enumerate}
\end{document}
